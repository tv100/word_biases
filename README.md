# Word Biases

Quick and simple Jupyter notebook used to check gender, race and religion stereotypes in public pre-trained Word2Vec models.

For a better understanding of this subject (and some mitigating solutions) check the following paper: 
[Man is to Computer Programmer as Woman is to
Homemaker? Debiasing Word Embeddings](http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf) by 
Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, and Adam Kalai. Proceedings of [NIPS 2016](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings), https://github.com/tolga-b/debiaswe

Pre-trained Word2Vec models are available in several places. Pay attention to the license terms for each distribution. 
- [Google's original model: Long-term storage for Google Code Project Hosting](https://code.google.com/archive/p/word2vec/)
- [Stanford NLP's GloVe - Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
- [fastText - Word vectors for 157 languages](https://fasttext.cc/docs/en/crawl-vectors.html)
- https://www.kaggle.com/ (including domain specific)

